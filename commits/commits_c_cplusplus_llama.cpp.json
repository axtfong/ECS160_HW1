{
  "name": "llama.cpp",
  "ownerLogin": "ggml-org",
  "language": "C++",
  "commits": [
    {
      "sha": "a2e0088d9242bd9e57f8b852b05a6e47843b5a45",
      "message": "Revert \"ggml : Leverage the existing GGML_F32_VEC helpers to vectorize ggml_vâ€¦\" (#16723)\n\nThis reverts commit 19a5a3edfd306516cc419679d69d6435943b6816.",
      "modifiedFiles": [
        "ggml/src/ggml-cpu/vec.h"
      ]
    },
    {
      "sha": "9b9201f65a22c02cee8e300f58f480a588591227",
      "message": "webui: introduce OpenAI-compatible model selector in JSON payload (#16562)\n\n* webui: introduce OpenAI-compatible model selector in JSON payload\n\n* webui: restore OpenAI-Compatible model source of truth and unify metadata capture\n\nThis change re-establishes a single, reliable source of truth for the active model:\nfully aligned with the OpenAI-Compat API behavior\n\nIt introduces a unified metadata flow that captures the model field from both\nstreaming and non-streaming responses, wiring a new onModel callback through ChatService\nThe model name is now resolved directly from the API payload rather than relying on\nserver /props or UI assumptions\n\nChatStore records and persists the resolved model for each assistant message during\nstreaming, ensuring consistency across the UI and database\nType definitions for API and settings were also extended to include model metadata\nand the onModel callback, completing the alignment with OpenAI-Compat semantics\n\n* webui: address review feedback from allozaur\n\n* webui: move model selector into ChatForm (idea by @allozaur)\n\n* webui: make model selector more subtle and integrated into ChatForm\n\n* webui: replaced the Flowbite selector with a native Svelte dropdown\n\n* webui: add developer setting to toggle the chat model selector\n\n* webui: address review feedback from allozaur\n\nNormalized streamed model names during chat updates\nby trimming input and removing directory components before saving\nor persisting them, so the conversation UI shows only the filename\n\nForced model names within the chat form selector dropdown to render as\na single-line, truncated entry with a tooltip revealing the full name\n\n* webui: toggle displayed model source for legacy vs OpenAI-Compat modes\n\nWhen the selector is disabled, it falls back to the active server model name from /props\n\nWhen the model selector is enabled, the displayed model comes from the message metadata\n(the one explicitly selected and sent in the request)\n\n* Update tools/server/webui/src/lib/components/app/chat/ChatForm/ChatFormActions.svelte\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/constants/localstorage-keys.ts\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/components/app/chat/ChatForm/ChatFormModelSelector.svelte\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/components/app/chat/ChatMessages/ChatMessageAssistant.svelte\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/services/chat.ts\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/services/chat.ts\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* webui: refactor model selector and persistence helpers\n\n- Replace inline portal and event listeners with proper Svelte bindings\n- Introduce \u0027persisted\u0027 store helper for localStorage sync without runes\n- Extract \u0027normalizeModelName\u0027 utils + Vitest coverage\n- Simplify ChatFormModelSelector structure and cleanup logic\n\nReplaced the persisted store helper\u0027s use of \u0027$state/$effect\u0027 runes with\na plain TS implementation to prevent orphaned effect runtime errors\noutside component context\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* webui: document normalizeModelName usage with inline examples\n\n* Update tools/server/webui/src/lib/components/app/chat/ChatForm/ChatFormModelSelector.svelte\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/stores/models.svelte.ts\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* Update tools/server/webui/src/lib/stores/models.svelte.ts\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* webui: extract ModelOption type into dedicated models.d.ts\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* webui: refine ChatMessageAssistant displayedModel source logic\n\n* webui: stabilize dropdown, simplify model extraction, and init assistant model field\n\n* chore: update webui static build\n\n* Update tools/server/webui/src/lib/components/app/chat/ChatMessages/ChatMessageAssistant.svelte\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e\n\n* chore: npm format, update webui static build\n\n* webui: align sidebar trigger position, remove z-index glitch\n\n* chore: update webui build output\n\n---------\n\nCo-authored-by: Aleksander Grygier \u003caleksander.grygier@gmail.com\u003e",
      "modifiedFiles": [
        "tools/server/public/index.html.gz",
        "tools/server/webui/src/lib/components/app/chat/ChatForm/ChatFormActions.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatForm/ChatFormModelSelector.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatMessages/ChatMessageAssistant.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatSettings/ChatSettingsDialog.svelte",
        "tools/server/webui/src/lib/components/app/index.ts",
        "tools/server/webui/src/lib/components/ui/select/select-trigger.svelte",
        "tools/server/webui/src/lib/constants/localstorage-keys.ts",
        "tools/server/webui/src/lib/constants/settings-config.ts",
        "tools/server/webui/src/lib/services/chat.ts",
        "tools/server/webui/src/lib/services/models.ts",
        "tools/server/webui/src/lib/stores/chat.svelte.ts",
        "tools/server/webui/src/lib/stores/models.svelte.ts",
        "tools/server/webui/src/lib/stores/persisted.svelte.ts",
        "tools/server/webui/src/lib/stores/settings.svelte.ts",
        "tools/server/webui/src/lib/types/api.d.ts",
        "tools/server/webui/src/lib/types/models.d.ts",
        "tools/server/webui/src/lib/types/settings.d.ts",
        "tools/server/webui/src/lib/utils/model-names.test.ts",
        "tools/server/webui/src/lib/utils/model-names.ts",
        "tools/server/webui/src/lib/utils/portal-to-body.ts",
        "tools/server/webui/src/routes/+layout.svelte"
      ]
    },
    {
      "sha": "19a5a3edfd306516cc419679d69d6435943b6816",
      "message": "ggml : Leverage the existing GGML_F32_VEC helpers to vectorize ggml_vec_set_f32 for faster fills (#16522)\n\n* Leverage the existing GGML_F32_VEC helpers to broadcast the fill value across SIMD registers and store in vector-sized chunks, while retaining the scalar tail for leftover elements and non-SIMD builds.\n\n* Vectorize additional f32 helper loops\n\n* Normalize f32 helper tails for ggml vec ops\n\n---------\n\nCo-authored-by: Aaron \u003cshelhamer.aaron@gmail.com\u003e",
      "modifiedFiles": [
        "ggml/src/ggml-cpu/vec.h"
      ]
    },
    {
      "sha": "d8eaa26e4d9228df3aa46a930db60c8eaab67c1b",
      "message": "tests : fix test-thread-safety when compiling with multiple backends (#16699)\n\n* run one test per backend/device (even if it\u0027s the same device)",
      "modifiedFiles": [
        "tests/test-thread-safety.cpp"
      ]
    },
    {
      "sha": "9285325ce0174631c3cd6121d56084adc4ef2d8f",
      "message": "CUDA: fix bug in topk-moe softmax (#16711)",
      "modifiedFiles": [
        "ggml/src/ggml-cuda/topk-moe.cu"
      ]
    },
    {
      "sha": "03792ad93609fc67e41041c6347d9aa14e5e0d74",
      "message": "CUDA: topk-moe: add optional parameter for gpt-oss (#16649)",
      "modifiedFiles": [
        "ggml/src/ggml-cuda/ggml-cuda.cu",
        "ggml/src/ggml-cuda/topk-moe.cu",
        "ggml/src/ggml-cuda/topk-moe.cuh",
        "tests/test-backend-ops.cpp"
      ]
    },
    {
      "sha": "51d1a8c997bd2629ef211a30208058ea87a30982",
      "message": "CUDA: better error for FA kernel with 0 occupancy (#16643)",
      "modifiedFiles": [
        "ggml/src/ggml-cuda/fattn-common.cuh"
      ]
    },
    {
      "sha": "4926419c4d74a1cf724e7163d937eb72f36e7b26",
      "message": "ggml: add ggml_can_fuse_subgraph (#16662)\n\n* ggml: add ggml_can_fuse_subgraph\n\n* ggml-cuda: use ggml_can_fuse_subgraph for topk-moe\n\n* format\n\n* 1. remove inputs from signature as they are transient nodes\n2. add check for views: view_src should be part of the subgraph\n\n* - combine check into one loop\n- check all view_src parents\n- other minor review comments\n\n* remove redudant if test\n\n* - rename and other minor review comments\n\n* add assert about count \u003c 32",
      "modifiedFiles": [
        "ggml/src/ggml-cuda/ggml-cuda.cu",
        "ggml/src/ggml-impl.h",
        "ggml/src/ggml.c"
      ]
    },
    {
      "sha": "6ea37f57391d27736c35cd3c20c1f990b7952b74",
      "message": "opencl: fix warnings and clean up profiling (#16688)\n\n* opencl: remove unused headers, fix warnings\n\n* opencl: clean up profiling, only keep kernel time",
      "modifiedFiles": [
        "ggml/src/ggml-opencl/ggml-opencl.cpp"
      ]
    },
    {
      "sha": "fb349848f387f355450c3187556e71e6d32c145f",
      "message": "vulkan: Handle FA with all -inf mask values (#16447)",
      "modifiedFiles": [
        "ggml/src/ggml-vulkan/vulkan-shaders/flash_attn.comp",
        "ggml/src/ggml-vulkan/vulkan-shaders/flash_attn_cm1.comp",
        "ggml/src/ggml-vulkan/vulkan-shaders/flash_attn_cm2.comp",
        "ggml/src/ggml-vulkan/vulkan-shaders/flash_attn_split_k_reduce.comp"
      ]
    },
    {
      "sha": "6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2",
      "message": "sycl : add PAD_REFLECT_D1 operator support (#16145)\n\n* sycl: add PAD_REFLECT_D1 operator support\n\n* docs(ops): regenerate docs/ops.md\n\n* remove trailing whitespaces\n\n* style: fix editorconfig issues â€” trim trailing spaces and normalize EOLs\n\n* fix: move PAD_REFLECT_1D case outside of fall-through block",
      "modifiedFiles": [
        "docs/ops.md",
        "docs/ops/SYCL.csv",
        "ggml/src/ggml-sycl/backend.hpp",
        "ggml/src/ggml-sycl/ggml-sycl.cpp",
        "ggml/src/ggml-sycl/pad_reflect_1d.cpp",
        "ggml/src/ggml-sycl/pad_reflect_1d.hpp"
      ]
    },
    {
      "sha": "84bf3c677857279037adf67cdcfd89eaa4ca9281",
      "message": "model : add BailingMoeV2 support (#16063)\n\n* add BailingMoeV2 support\n\n* update llm types\n\n* undo\n\n* undo\n\n* update llm types\n\n* add model collection link\n\n* update\n\n* almost working\n\n* correct group selection and rename n_group_exp\n\n* avoid large top_k and use argmax instead for now\n\nif we had something like argmax2 that would be equivalent, but this works fine until then\n\n* poke\n\n* skip group selection when there are no tokens\n\n* fix 1T conversion\n\n* hopefully fixed expert group selection\n\nthird time\u0027s the charm?\n\n* make expert group selection generally available\n\nThe new LLaDA2Moe model uses this method too, make it generally available regardless of architecture.\n\n* allow n_expert_groups to be 1 (Kimi K2)\n\n* address review suggestions",
      "modifiedFiles": [
        "README.md",
        "convert_hf_to_gguf.py",
        "convert_hf_to_gguf_update.py",
        "gguf-py/gguf/constants.py",
        "gguf-py/gguf/gguf_writer.py",
        "gguf-py/gguf/tensor_mapping.py",
        "src/llama-arch.cpp",
        "src/llama-arch.h",
        "src/llama-chat.cpp",
        "src/llama-chat.h",
        "src/llama-graph.cpp",
        "src/llama-hparams.h",
        "src/llama-model.cpp",
        "src/llama-model.h",
        "src/llama-vocab.cpp"
      ]
    },
    {
      "sha": "c9c1972e2c2cc6a771fcc145bfa138700179f961",
      "message": "Handle legacy \u0027context\u0027 attachments (#16687)",
      "modifiedFiles": [
        "tools/server/public/index.html.gz",
        "tools/server/webui/src/app.d.ts",
        "tools/server/webui/src/lib/components/app/chat/ChatAttachments/ChatAttachmentsList.svelte",
        "tools/server/webui/src/lib/services/chat.ts",
        "tools/server/webui/src/lib/types/database.d.ts"
      ]
    },
    {
      "sha": "b617cfd2896edd592a36ebbc041817eb030a1005",
      "message": "ggml-alloc : fix leak when reusing a tensor with a larger size (#16679)",
      "modifiedFiles": [
        "ggml/src/ggml-alloc.c"
      ]
    },
    {
      "sha": "79068501fac9a74cca7129a8e5a8281b410a853e",
      "message": "Prevent premature submission on IME input (#16673)\n\n* fix: Prevent premature submission on IME input\n\n* chore: update webui static build\n\n* refactor: Put IME completion checker in a helper function and add checking for `KeyboardEvent.eventKey \u003d\u003d\u003d 229`\n\n* chore: update webui static build\n\n* chore: update webui static build\n\n* chore: update webui static build",
      "modifiedFiles": [
        "tools/server/public/index.html.gz",
        "tools/server/webui/src/lib/components/app/chat/ChatForm/ChatForm.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatMessages/ChatMessage.svelte",
        "tools/server/webui/src/lib/utils/is-ime-composing.ts"
      ]
    },
    {
      "sha": "0e4a0cf2fae667d3efcf52f2f52398779d986b1d",
      "message": "Import/Export UX improvements (#16619)\n\n* webui : added download action (#13552)\n\n* webui : import and export (for all conversations)\n\n* webui : fixed download-format, import of one conversation\n\n* webui : add ExportedConversations type for chat import/export\n\n* feat: Update naming \u0026 order\n\n* chore: Linting\n\n* feat: Import/Export UX improvements\n\n* chore: update webui build output\n\n* feat: Update UI placement of Import/Export tab in Chat Settings Dialog\n\n* refactor: Cleanup\n\nchore: update webui build output\n\n* feat: Enable shift-click multiple conversation items selection\n\n* chore: update webui static build\n\n* chore: update webui static build\n\n---------\n\nCo-authored-by: Sascha Rogmann \u003cgithub@rogmann.org\u003e",
      "modifiedFiles": [
        "tools/server/public/index.html.gz",
        "tools/server/webui/src/lib/components/app/chat/ChatSettings/ChatSettingsDialog.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatSettings/ConversationSelectionDialog.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatSettings/ImportExportTab.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatSidebar/ChatSidebarActions.svelte",
        "tools/server/webui/src/lib/components/app/index.ts",
        "tools/server/webui/src/lib/stores/chat.svelte.ts",
        "tools/server/webui/src/lib/utils/conversation-utils.ts"
      ]
    },
    {
      "sha": "13f2cfad4170c096c51a02c24a6a158cb47f1480",
      "message": "Enable per-conversation loading states to allow having parallel conversations (#16327)\n\n* feat: Per-conversation loading states and tracking streaming stats\n\n* chore: update webui build output\n\n* refactor: Chat state management\n\nConsolidates loading state management by using a global `isLoading` store synchronized with individual conversation states.\n\nThis change ensures proper reactivity and avoids potential race conditions when updating the UI based on the loading status of different conversations. It also improves the accuracy of statistics displayed.\n\nAdditionally, slots service methods are updated to use conversation IDs for per-conversation state management, avoiding global state pollution.\n\n* feat: Adds loading indicator to conversation items\n\n* chore: update webui build output\n\n* fix: Fix aborting chat streaming\n\nImproves the chat stream abortion process by ensuring that partial responses are saved before the abort signal is sent.\n\nThis avoids a race condition where the onError callback could clear the streaming state before the partial response is saved. Additionally, the stream reading loop and callbacks are now checked for abort signals to prevent further processing after abortion.\n\n* refactor: Remove redundant comments\n\n* chore: build webui static output\n\n* refactor: Cleanup\n\n* chore: update webui build output\n\n* chore: update webui build output\n\n* fix: Conversation loading indicator for regenerating messages\n\n* chore: update webui static build\n\n* feat: Improve configuration\n\n* feat: Install `http-server` as dev dependency to not need to rely on `npx` in CI",
      "modifiedFiles": [
        "tools/server/public/index.html.gz",
        "tools/server/webui/package-lock.json",
        "tools/server/webui/package.json",
        "tools/server/webui/playwright.config.ts",
        "tools/server/webui/src/lib/components/app/chat/ChatProcessingInfo.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatScreen/ChatScreen.svelte",
        "tools/server/webui/src/lib/components/app/chat/ChatSidebar/ChatSidebarConversationItem.svelte",
        "tools/server/webui/src/lib/services/chat.ts",
        "tools/server/webui/src/lib/services/slots.ts",
        "tools/server/webui/src/lib/stores/chat.svelte.ts",
        "tools/server/webui/src/routes/chat/[id]/+page.svelte",
        "tools/server/webui/svelte.config.js",
        "tools/server/webui/vite.config.ts"
      ]
    },
    {
      "sha": "06332e28672356b964d6dfc2ba4657e20581cd43",
      "message": "llama-batch: fix build fails with `-Werror\u003dmissing-braces` (#16614)\n\n## Why it failed\n\nWhen compiling with strict compiler flags (-Wmissing-braces -Werror\u003dmissing-braces),\nthe build fails with the following error:\n\n```\ncmake \\\n  -S . \\\n  -B ../llama.cpp.build \\\n  --preset\u003dx64-linux-gcc-debug \\\n  -DCMAKE_INSTALL_PREFIX\u003d/tmp/local \\\n  -DCMAKE_CXX_FLAGS\u003d\"-Wmissing-braces -Werror\u003dmissing-braces\" \u0026\u0026 \\\ncmake --build ../llama.cpp.build/\n...\nIn file included from /home/otegami/work/cpp/llama.cpp/src/llama-graph.h:4,\n                 from /home/otegami/work/cpp/llama.cpp/src/llama-model.h:5,\n                 from /home/otegami/work/cpp/llama.cpp/src/llama.cpp:8:\n/home/otegami/work/cpp/llama.cpp/src/llama-batch.h:126:48: error: missing braces around initializer for \u0027std::__array_traits\u003cint, 1\u003e::_Type\u0027 {aka \u0027int [1]\u0027} [-Werror\u003dmissing-braces]\n  126 |     std::array\u003cllama_seq_id, 1\u003e seq_id_0 \u003d { 0 }; // default sequence id\n      |                                                ^\ncc1plus: some warnings being treated as errors\n```\n\nThe issue is that std::array initialization requires double braces.\n\n## How to fix\n\nThis PR changes `{ 0 }` to `{{ 0 }}` for std::array initialization.\n\nThis is part of a series of commits to fix missing braces warnings across the codebase.\n- src/llama-batch.h \u003c- This PR is here.\n- src/llama-context.cpp\n- tests/test-backend-ops.cpp\n- tests/test-gguf.cpp\n- tools/mtmd/clip.cpp\n\nBenefits:\n- std::array is a struct containing a C-style array, requiring nested braces\n- Enables stricter compiler warnings to catch potential issues",
      "modifiedFiles": [
        "src/llama-batch.h"
      ]
    },
    {
      "sha": "72d53e6c4decee8b339e49aed8cc0e234b9639dc",
      "message": "readme: update bindings (#16651)\n\nSigned-off-by: deadprogram \u003cron@hybridgroup.com\u003e",
      "modifiedFiles": [
        "README.md"
      ]
    },
    {
      "sha": "2330de7b847ca84eac766df372c604c26db72747",
      "message": "SYCL: Add support for FLOOR,CEIL,ROUND and TRUNC unary operators (#16613)\n\n* SYCL: Add support for FLOOR,CEIL,ROUND and TRUNC unary operators\n\nClean up unrelated changes from previous commit\n\n* Chore: remove empty lines and fix indentation\n\n* Clean up: remove leftover blank lines and fix spacing\n\n* chore: fix trailing whitespace and ensure final newline\n\n* Cleanup: remove redundant declarations already defined in header\n\n* Sync docs/ops.md with updated backend operation support\n\n* docs: update ops.md after rebase\n\n* docs: update ops.md - Vulkan supports SSM_CONV and SSM_SCAN",
      "modifiedFiles": [
        "docs/ops.md",
        "docs/ops/SYCL.csv",
        "docs/ops/Vulkan.csv",
        "ggml/src/ggml-sycl/element_wise.cpp",
        "ggml/src/ggml-sycl/element_wise.hpp",
        "ggml/src/ggml-sycl/ggml-sycl.cpp",
        "tests/test-backend-ops.cpp"
      ]
    }
  ],
  "forks": [
    {
      "name": "llama.cpp",
      "ownerLogin": "sultanqasim",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "OpenMOSE",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "maifeeulasad",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "progray",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "JJJYmmm",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "csyslabs",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "hungryDodo",
      "commitCount": 0
    },
    {
      "name": "llama.cpp.manni",
      "ownerLogin": "ManfredAabye",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "ZolotarevaLyubov",
      "commitCount": 0
    },
    {
      "name": "llama.cpp",
      "ownerLogin": "Adityarya11",
      "commitCount": 0
    }
  ]
}